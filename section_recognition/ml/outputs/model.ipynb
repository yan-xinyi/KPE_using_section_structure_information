{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 在所有特征下各模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\app_installer\\anconda\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from configs import COLUMNS, LABELS2IDS\n",
    "from utils import *\n",
    "\n",
    "# 设置随机种子\n",
    "set_seed(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. 读取数据和数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec_titles_vec: (7405, 1253)\n",
      "sec_subtitles_vec: (7405, 1175)\n",
      "sec_texts_vec: (7405, 1491)\n",
      "14 (7405, 3930) (7405,)\n"
     ]
    }
   ],
   "source": [
    "# 读取预处理的数据\n",
    "annotated_datas = pd.read_table('../annotated_datas.xls', names=COLUMNS)\n",
    "\n",
    "# 获取数据\n",
    "p_ids = annotated_datas['p_id'].values\n",
    "sec_titles = annotated_datas['sec_title'].values\n",
    "sec_subtitles = annotated_datas['sec_subtitle'].values\n",
    "sec_texts = annotated_datas['sec_text'].values\n",
    "\n",
    "# headers补充空值\n",
    "sec_subtitles_new = []\n",
    "for sec_subtitle, sec_title in zip(sec_subtitles, sec_titles):\n",
    "    if str(sec_subtitle) == 'nan': \n",
    "        sec_subtitles_new.append(sec_title)\n",
    "    else:\n",
    "        sec_subtitles_new.append(sec_subtitle)\n",
    "sec_subtitles = np.array(sec_subtitles_new)\n",
    "\n",
    "dataset_ids = annotated_datas['dataset_id'].values.reshape(-1, 1)\n",
    "jname_ids = annotated_datas['jname_id'].values.reshape(-1, 1)\n",
    "\n",
    "bib_nums = annotated_datas['bib_num'].values.reshape(-1, 1)\n",
    "fn_nums = annotated_datas['fn_num'].values.reshape(-1, 1)\n",
    "fig_nums = annotated_datas['fig_num'].values.reshape(-1, 1)\n",
    "tab_nums = annotated_datas['tab_num'].values.reshape(-1, 1)\n",
    "equ_nums = annotated_datas['equ_num'].values.reshape(-1, 1)\n",
    "\n",
    "para_nums = annotated_datas['para_num'].values.reshape(-1, 1)\n",
    "sen_nums = annotated_datas['sen_num'].values.reshape(-1, 1)\n",
    "word_nums = annotated_datas['word_num'].values.reshape(-1, 1)\n",
    "\n",
    "sec_locs = annotated_datas['sec_loc'].values.reshape(-1, 1)  \n",
    "        \n",
    "ys = np.array([LABELS2IDS[anno_result] for anno_result in annotated_datas['label']])\n",
    "\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "sec_titles_vec = preprocessing_titles(sec_titles, save_name='sec_title_words')\n",
    "sec_subtitles_vec = preprocessing_titles(sec_subtitles, ys, feature_selection_approach = 'CHI', percentile=20, save_name='sec_subtitle_words')\n",
    "sec_texts_vec = preprocessing_text(sec_texts, ys, feature_selection_approach = 'CHI', percentile=10, save_name='sec_text_words')\n",
    "print(\"sec_titles_vec:\", sec_titles_vec.shape)\n",
    "print(\"sec_subtitles_vec:\", sec_subtitles_vec.shape)\n",
    "print(\"sec_texts_vec:\", sec_texts_vec.shape)\n",
    "\n",
    "features = [sec_titles_vec, sec_subtitles_vec, sec_texts_vec, \n",
    "             dataset_ids, jname_ids, bib_nums, fn_nums,\n",
    "             fig_nums, tab_nums, equ_nums, para_nums, \n",
    "             sen_nums, word_nums, sec_locs]\n",
    "\n",
    "save_datas = []\n",
    "xs = hstack(features).toarray()\n",
    "print(len(features), xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. 给章节文本选择合适的特征数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* NB *************************\n",
      "--------------------------------------------------\n",
      "[[66.53 79.92 66.48]\n",
      " [90.61 98.59 93.2 ]\n",
      " [71.83 87.79 74.65]\n",
      " [85.98 98.98 89.15]\n",
      " [65.57 64.14 64.84]]\n",
      "INFO: NB, PMC->P:76.1, R:85.88, F1:77.66\n",
      "----------------------------------------\n",
      "[[75.45 72.86 73.53]\n",
      " [72.78 68.93 70.4 ]\n",
      " [74.64 88.09 73.86]\n",
      " [74.33 70.57 71.91]\n",
      " [76.22 73.1  74.21]]\n",
      "INFO: NB, LIS->P:74.68, R:74.71, F1:72.78\n",
      "----------------------------------------\n",
      "[[79.83 90.8  77.48]\n",
      " [78.49 74.82 76.55]\n",
      " [77.1  75.01 76.  ]\n",
      " [79.02 75.93 77.42]\n",
      " [80.   91.61 78.18]]\n",
      "INFO: NB, IEEE->P:78.89, R:81.63, F1:77.13\n",
      "----------------------------------------\n",
      "[[77.87 86.13 76.98]\n",
      " [76.53 84.91 75.8 ]\n",
      " [76.37 85.4  76.2 ]\n",
      " [77.44 92.23 76.99]\n",
      " [78.17 83.71 77.11]]\n",
      "INFO: NB, ALL->P:77.28, R:86.48, F1:76.62\n",
      "----------------------------------------\n",
      "[[98.53918472 97.57195219 98.05287886]\n",
      " [78.94901087 84.9581801  81.82528626]\n",
      " [93.59425599 82.10115589 87.45933116]\n",
      " [92.54443694 88.05667111 90.23684823]\n",
      " [97.16917162 96.15814142 96.65785087]\n",
      " [ 2.86381405 70.          5.47593052]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9854    0.9758    0.9806      1526\n",
      "           1     0.7885    0.8495    0.8179       711\n",
      "           2     0.9360    0.8212    0.8748      1745\n",
      "           3     0.9253    0.8805    0.9024      1590\n",
      "           4     0.9717    0.9616    0.9666      1821\n",
      "           5     0.0284    0.6667    0.0544        12\n",
      "\n",
      "    accuracy                         0.9028      7405\n",
      "   macro avg     0.7726    0.8592    0.7661      7405\n",
      "weighted avg     0.9370    0.9028    0.9183      7405\n",
      "\n",
      "==================================================\n",
      "************************* LR *************************\n",
      "--------------------------------------------------\n",
      "[[74.72 98.8  79.25]\n",
      " [91.67 99.81 94.35]\n",
      " [79.65 90.38 82.22]\n",
      " [69.44 82.44 70.97]\n",
      " [82.54 74.04 76.9 ]]\n",
      "INFO: LR, PMC->P:79.6, R:89.09, F1:80.74\n",
      "----------------------------------------\n",
      "[[95.88 95.71 95.78]\n",
      " [77.45 76.96 77.13]\n",
      " [78.87 79.02 78.93]\n",
      " [91.66 91.08 91.25]\n",
      " [77.94 77.78 77.83]]\n",
      "INFO: LR, LIS->P:84.36, R:84.11, F1:84.18\n",
      "----------------------------------------\n",
      "[[81.2  80.25 80.62]\n",
      " [96.78 96.81 96.8 ]\n",
      " [96.32 96.03 96.16]\n",
      " [96.78 96.09 96.41]\n",
      " [81.14 80.85 80.97]]\n",
      "INFO: LR, IEEE->P:90.44, R:90.01, F1:90.19\n",
      "----------------------------------------\n",
      "[[87.21 91.15 88.61]\n",
      " [90.84 90.61 90.72]\n",
      " [88.18 85.45 86.53]\n",
      " [82.22 95.53 83.89]\n",
      " [80.2  79.86 80.02]]\n",
      "INFO: LR, ALL->P:85.73, R:88.52, F1:85.95\n",
      "----------------------------------------\n",
      "[[99.46347677 97.05665766 98.24273748]\n",
      " [92.46683848 91.25275425 91.85118457]\n",
      " [92.09289658 96.04628298 94.02736255]\n",
      " [96.78498117 94.65488373 95.70405148]\n",
      " [98.9019839  98.7978258  98.84695542]\n",
      " [34.66666667 53.33333333 37.04761905]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9946    0.9705    0.9824      1526\n",
      "           1     0.9245    0.9128    0.9186       711\n",
      "           2     0.9209    0.9605    0.9403      1745\n",
      "           3     0.9678    0.9465    0.9571      1590\n",
      "           4     0.9890    0.9879    0.9885      1821\n",
      "           5     0.3000    0.5000    0.3750        12\n",
      "\n",
      "    accuracy                         0.9610      7405\n",
      "   macro avg     0.8495    0.8797    0.8603      7405\n",
      "weighted avg     0.9623    0.9610    0.9614      7405\n",
      "\n",
      "==================================================\n",
      "************************* SVM *************************\n",
      "--------------------------------------------------\n",
      "[[87.21 97.99 89.77]\n",
      " [90.94 90.98 88.18]\n",
      " [86.44 89.02 83.53]\n",
      " [82.75 82.65 82.7 ]\n",
      " [64.69 65.11 64.85]]\n",
      "INFO: SVM, PMC->P:82.41, R:85.15, F1:81.81\n",
      "----------------------------------------\n",
      "[[76.33 74.34 74.61]\n",
      " [75.12 71.55 72.19]\n",
      " [75.8  73.65 73.89]\n",
      " [88.6  84.54 85.36]\n",
      " [90.52 86.59 87.38]]\n",
      "INFO: SVM, LIS->P:81.27, R:78.13, F1:78.69\n",
      "----------------------------------------\n",
      "[[73.35 69.82 69.7 ]\n",
      " [89.92 86.3  85.31]\n",
      " [89.6  86.94 86.94]\n",
      " [89.41 86.71 86.61]\n",
      " [74.13 70.5  70.39]]\n",
      "INFO: SVM, IEEE->P:83.28, R:80.05, F1:79.79\n",
      "----------------------------------------\n",
      "[[93.21 79.42 82.78]\n",
      " [92.95 78.55 82.05]\n",
      " [92.84 79.41 82.77]\n",
      " [93.02 90.02 90.86]\n",
      " [76.37 72.82 73.66]]\n",
      "INFO: SVM, ALL->P:89.68, R:80.04, F1:82.42\n",
      "----------------------------------------\n",
      "[[99.79774923 96.85570685 98.30419124]\n",
      " [95.61172698 76.19682819 84.77531531]\n",
      " [93.16734933 73.12017049 81.90589099]\n",
      " [69.94691857 97.10764781 81.30068961]\n",
      " [99.55070597 96.97804078 98.24600546]\n",
      " [80.         40.         50.        ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9980    0.9685    0.9830      1526\n",
      "           1     0.9559    0.7623    0.8482       711\n",
      "           2     0.9314    0.7312    0.8193      1745\n",
      "           3     0.6990    0.9711    0.8128      1590\n",
      "           4     0.9955    0.9698    0.9825      1821\n",
      "           5     1.0000    0.3333    0.5000        12\n",
      "\n",
      "    accuracy                         0.8926      7405\n",
      "   macro avg     0.9300    0.7894    0.8243      7405\n",
      "weighted avg     0.9134    0.8926    0.8940      7405\n",
      "\n",
      "==================================================\n",
      "************************* RF *************************\n",
      "--------------------------------------------------\n",
      "[[91.24 99.45 93.95]\n",
      " [82.96 83.15 83.05]\n",
      " [82.06 74.13 76.7 ]\n",
      " [99.65 99.69 99.67]\n",
      " [65.88 66.37 66.12]]\n",
      "INFO: RF, PMC->P:84.36, R:84.56, F1:83.9\n",
      "----------------------------------------\n",
      "[[79.24 79.26 79.23]\n",
      " [77.67 77.64 77.62]\n",
      " [79.2  79.31 79.25]\n",
      " [94.01 93.28 93.53]\n",
      " [93.84 93.58 93.66]]\n",
      "INFO: RF, LIS->P:84.79, R:84.61, F1:84.66\n",
      "----------------------------------------\n",
      "[[81.12 79.84 80.34]\n",
      " [98.18 96.04 96.94]\n",
      " [96.63 95.6  96.02]\n",
      " [96.89 95.03 95.83]\n",
      " [81.53 80.88 81.16]]\n",
      "INFO: RF, IEEE->P:90.87, R:89.48, F1:90.06\n",
      "----------------------------------------\n",
      "[[97.39 85.76 88.77]\n",
      " [96.85 90.47 93.06]\n",
      " [96.9  85.4  88.35]\n",
      " [97.04 96.07 96.5 ]\n",
      " [80.58 80.   80.25]]\n",
      "INFO: RF, ALL->P:93.75, R:87.54, F1:89.39\n",
      "----------------------------------------\n",
      "[[99.60415729 98.82442708 99.21144105]\n",
      " [95.63547309 89.13781551 92.26663965]\n",
      " [92.15853073 97.58759297 94.79418944]\n",
      " [96.2616519  95.16418717 95.69989682]\n",
      " [98.83714673 97.86232344 98.34415439]\n",
      " [80.         46.66666667 56.        ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9960    0.9882    0.9921      1526\n",
      "           1     0.9563    0.8917    0.9229       711\n",
      "           2     0.9215    0.9759    0.9480      1745\n",
      "           3     0.9625    0.9516    0.9570      1590\n",
      "           4     0.9884    0.9786    0.9834      1821\n",
      "           5     1.0000    0.4167    0.5882        12\n",
      "\n",
      "    accuracy                         0.9649      7405\n",
      "   macro avg     0.9708    0.8671    0.8986      7405\n",
      "weighted avg     0.9656    0.9649    0.9647      7405\n",
      "\n",
      "==================================================\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# 算法1：朴素贝叶斯\n",
    "print(\"*\"*25, \"NB\", \"*\"*25)\n",
    "model1 = MultinomialNB()\n",
    "p, r, f1 = execute_model(model1, xs,  ys, dataset_ids, info=\"NB\", is_output_dataset_results=True)\n",
    "save_datas.append([\"NB\", p, r, f1])\n",
    "\n",
    "# # 算法2：决策树\n",
    "# print(\"*\"*25, \"DT\", \"*\"*25)\n",
    "# model2 = DecisionTreeClassifier(class_weight=\"balanced\", random_state=2022)\n",
    "# p, r, f1 = execute_model(model2, xs,  ys, dataset_ids, info=\"DT\", is_output_dataset_results=True)\n",
    "# save_datas.append([\"DT\", p, r, f1])\n",
    "\n",
    "# # 算法3：K-近邻\n",
    "# print(\"*\"*25, \"KNN\", \"*\"*25)\n",
    "# model3 = KNeighborsClassifier()\n",
    "# p, r, f1 = execute_model(model3, xs,  ys, dataset_ids, info=\"KNN\", is_output_dataset_results=True)\n",
    "# save_datas.append([\"KNN\", p, r, f1])\n",
    "\n",
    "# 算法4：逻辑斯蒂回归\n",
    "print(\"*\"*25, \"LR\", \"*\"*25)\n",
    "model4 = LogisticRegression(class_weight='balanced', random_state=2022)\n",
    "p, r, f1 = execute_model(model4, xs,  ys, dataset_ids, info=\"LR\", is_output_dataset_results=True)\n",
    "save_datas.append([\"LR\", p, r, f1])\n",
    "\n",
    "# 算法5：支持向量机\n",
    "print(\"*\"*25, \"SVM\", \"*\"*25)\n",
    "model5 = SVC(class_weight='balanced', random_state=2022)\n",
    "p, r, f1 = execute_model(model5, xs,  ys, dataset_ids, info=\"SVM\", is_output_dataset_results=True)\n",
    "save_datas.append([\"SVM\", p, r, f1])\n",
    "\n",
    "# # 算法6：多层感知机\n",
    "# print(\"*\"*25, \"MLP\", \"*\"*25)\n",
    "# model6 = MLPClassifier(solver='adam', alpha=0.001, batch_size='auto',\n",
    "# learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=500, shuffle=True,\n",
    "# random_state=2022, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "# early_stopping=True, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# p, r, f1 = execute_model(model6, xs,  ys, dataset_ids, info=\"MLP\", is_output_dataset_results=True)\n",
    "# save_datas.append([\"MLP\", p, r, f1])\n",
    "\n",
    "# 算法7：随机森林量机\n",
    "print(\"*\"*25, \"RF\", \"*\"*25)\n",
    "model7 = RandomForestClassifier(class_weight='balanced', random_state=2022)\n",
    "p, r, f1 = execute_model(model7, xs,  ys, dataset_ids, info=\"RF\", is_output_dataset_results=True)\n",
    "save_datas.append([\"RF\", p, r, f1])\n",
    "\n",
    "# # 算法8：ADA\n",
    "# print(\"*\"*25, \"ADA\", \"*\"*25)\n",
    "# model8 = AdaBoostClassifier(random_state=2022)\n",
    "# p, r, f1 = execute_model(model8, xs,  ys, dataset_ids, info=\"ADA\")\n",
    "# save_datas.append([\"ADA\", p, r, f1])\n",
    "\n",
    "# # 算法9：xgboost\n",
    "# print(\"*\"*25, \"XGB\", \"*\"*25)\n",
    "# model9 = XGBClassifier(seed=2022, use_label_encoder=False, eval_metric=['logloss','auc','error'])\n",
    "# p, r, f1 = execute_model(model9, xs,  ys, dataset_ids, info=\"XGB\")\n",
    "# save_datas.append([\"XGB\", p, r, f1])\n",
    "\n",
    "print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NB', 77.28, 86.48, 76.62],\n",
       " ['LR', 85.73, 88.52, 85.95],\n",
       " ['SVM', 89.68, 80.04, 82.42],\n",
       " ['RF', 93.75, 87.54, 89.39]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_datas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% raw\n"
    }
   },
   "source": [
    "# 投票集成\n",
    "model = VotingClassifier(estimators=[('RF', model7),('XGB', model9)], voting='soft')\n",
    "p, r, f1 = execute_model(model, xs,  ys, dataset_ids, info=\"VOT\")\n",
    "print(p, r, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#  # 算法5：支持向量机\n",
    "# print(\"*\"*25, \"SVM\", \"*\"*25)\n",
    "# model5 = SVC(kernel='linear', class_weight='balanced', random_state=2022)\n",
    "# p, r, f1 = execute_model(model5, xs,  ys, dataset_ids, info=\"SVM\", is_output_dataset_results=True)\n",
    "# save_datas.append([\"SVM\", p, r, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* RF *************************\n",
      "--------------------------------------------------\n",
      "[[91.24 99.45 93.95]\n",
      " [82.96 83.15 83.05]\n",
      " [82.06 74.13 76.7 ]\n",
      " [99.65 99.69 99.67]\n",
      " [65.88 66.37 66.12]]\n",
      "INFO: RF, PMC->P:84.36, R:84.56, F1:83.9\n",
      "----------------------------------------\n",
      "[[79.24 79.26 79.23]\n",
      " [77.67 77.64 77.62]\n",
      " [79.2  79.31 79.25]\n",
      " [94.01 93.28 93.53]\n",
      " [94.01 93.86 93.9 ]]\n",
      "INFO: RF, LIS->P:84.83, R:84.67, F1:84.71\n",
      "----------------------------------------\n",
      "[[81.12 79.84 80.34]\n",
      " [98.18 96.04 96.94]\n",
      " [96.63 95.6  96.02]\n",
      " [96.89 95.03 95.83]\n",
      " [81.53 80.88 81.16]]\n",
      "INFO: RF, IEEE->P:90.87, R:89.48, F1:90.06\n",
      "----------------------------------------\n",
      "[[97.39 85.76 88.77]\n",
      " [96.85 90.47 93.06]\n",
      " [96.9  85.4  88.35]\n",
      " [97.04 96.07 96.5 ]\n",
      " [80.62 80.12 80.34]]\n",
      "INFO: RF, ALL->P:93.76, R:87.56, F1:89.4\n",
      "----------------------------------------\n",
      "[[99.60415729 98.82442708 99.21144105]\n",
      " [95.63989543 89.2767044  92.34296569]\n",
      " [92.20928304 97.58759297 94.82082562]\n",
      " [96.2616519  95.16418717 95.69989682]\n",
      " [98.83714673 97.86232344 98.34415439]\n",
      " [80.         46.66666667 56.        ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9960    0.9882    0.9921      1526\n",
      "           1     0.9563    0.8931    0.9236       711\n",
      "           2     0.9220    0.9759    0.9482      1745\n",
      "           3     0.9625    0.9516    0.9570      1590\n",
      "           4     0.9884    0.9786    0.9834      1821\n",
      "           5     1.0000    0.4167    0.5882        12\n",
      "\n",
      "    accuracy                         0.9650      7405\n",
      "   macro avg     0.9709    0.8673    0.8988      7405\n",
      "weighted avg     0.9657    0.9650    0.9649      7405\n",
      "\n",
      "==================================================\n",
      "************************* XGB *************************\n",
      "--------------------------------------------------\n",
      "[[99.87 99.85 99.86]\n",
      " [82.62 82.8  82.71]\n",
      " [99.1  90.94 93.62]\n",
      " [83.21 83.04 83.12]\n",
      " [82.74 74.7  77.33]]\n",
      "INFO: XGB, PMC->P:89.51, R:86.27, F1:87.33\n",
      "----------------------------------------\n",
      "[[79.82 79.91 79.86]\n",
      " [78.37 78.03 78.15]\n",
      " [97.02 97.07 97.04]\n",
      " [93.62 93.23 93.36]\n",
      " [95.24 95.29 95.25]]\n",
      "INFO: XGB, LIS->P:88.81, R:88.71, F1:88.73\n",
      "----------------------------------------\n",
      "[[97.91 96.92 97.32]\n",
      " [97.93 97.3  97.6 ]\n",
      " [94.71 94.56 94.61]\n",
      " [97.8  97.6  97.7 ]\n",
      " [82.07 81.68 81.84]]\n",
      "INFO: XGB, IEEE->P:94.08, R:93.61, F1:93.81\n",
      "----------------------------------------\n",
      "[[97.86 91.84 94.28]\n",
      " [97.17 90.98 93.5 ]\n",
      " [96.74 91.21 93.41]\n",
      " [97.11 97.01 97.06]\n",
      " [81.29 81.01 81.14]]\n",
      "INFO: XGB, ALL->P:94.03, R:90.41, F1:91.88\n",
      "----------------------------------------\n",
      "[[99.60481011 98.82442708 99.2119764 ]\n",
      " [95.72694389 92.9592856  94.3038224 ]\n",
      " [93.72215857 96.67482697 95.17418675]\n",
      " [96.61849198 95.16299151 95.88240558]\n",
      " [98.52643944 98.85189959 98.68692722]\n",
      " [80.         60.         68.        ]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9960    0.9882    0.9921      1526\n",
      "           1     0.9566    0.9297    0.9429       711\n",
      "           2     0.9372    0.9668    0.9518      1745\n",
      "           3     0.9662    0.9516    0.9588      1590\n",
      "           4     0.9852    0.9885    0.9868      1821\n",
      "           5     1.0000    0.5833    0.7368        12\n",
      "\n",
      "    accuracy                         0.9691      7405\n",
      "   macro avg     0.9735    0.9013    0.9282      7405\n",
      "weighted avg     0.9693    0.9691    0.9690      7405\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 算法7：随机森林量机\n",
    "print(\"*\"*25, \"RF\", \"*\"*25)\n",
    "model7 = RandomForestClassifier(class_weight='balanced', random_state=2022)\n",
    "p, r, f1 = execute_model(model7, xs,  ys, dataset_ids, info=\"RF\", is_output_dataset_results=True)\n",
    "save_datas.append([\"RF\", p, r, f1])\n",
    "\n",
    "\n",
    "# 算法9：xgboost\n",
    "print(\"*\"*25, \"XGB\", \"*\"*25)\n",
    "model9 = XGBClassifier(seed=2022, use_label_encoder=False, eval_metric=['logloss','auc','error'])\n",
    "p, r, f1 = execute_model(model9, xs,  ys, dataset_ids, info=\"XGB\", is_output_dataset_results=True)\n",
    "save_datas.append([\"XGB\", p, r, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
